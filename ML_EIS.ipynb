{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "#import data\n",
    "df=pd.read_csv('dataProject.csv', header=0); \n",
    "\n",
    "X1=df.ix[:,2:154] #instances\n",
    "#X1.head()\n",
    "X=X1.values\n",
    "\n",
    "# standardscale data\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "X_scaled=preprocessing.scale(X)\n",
    "\n",
    "pca = PCA(n_components=2).fit(X_scaled)\n",
    "X_2d = pca.transform(X_scaled)\n",
    "\n",
    "#define lables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df.loc[:, 'Label'].values\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.15446284,  1.10876447,  1.52607931, ...,  0.5774746 ,\n",
       "         0.56047402,  0.56544483],\n",
       "       [ 1.38662783,  1.48333047,  1.39882512, ...,  0.60296381,\n",
       "         0.59291899,  0.58050281],\n",
       "       [ 1.42892982,  1.43603584,  1.46805018, ...,  0.58244149,\n",
       "         0.59227999,  0.5898822 ],\n",
       "       ..., \n",
       "       [-0.22226606, -0.27850703, -0.83096618, ..., -0.43245664,\n",
       "        -0.44620857, -0.44693524],\n",
       "       [-0.52049932, -0.75406175, -0.52962831, ..., -0.42768377,\n",
       "        -0.438642  , -0.43357673],\n",
       "       [-0.68848744, -0.41786123, -0.46313112, ..., -0.45367787,\n",
       "        -0.44543701, -0.43981809]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.15446284,  1.10876447,  1.52607931, ...,  0.5774746 ,\n",
       "         0.56047402,  0.56544483],\n",
       "       [ 1.38662783,  1.48333047,  1.39882512, ...,  0.60296381,\n",
       "         0.59291899,  0.58050281],\n",
       "       [ 1.42892982,  1.43603584,  1.46805018, ...,  0.58244149,\n",
       "         0.59227999,  0.5898822 ],\n",
       "       ..., \n",
       "       [-0.22226606, -0.27850703, -0.83096618, ..., -0.43245664,\n",
       "        -0.44620857, -0.44693524],\n",
       "       [-0.52049932, -0.75406175, -0.52962831, ..., -0.42768377,\n",
       "        -0.438642  , -0.43357673],\n",
       "       [-0.68848744, -0.41786123, -0.46313112, ..., -0.45367787,\n",
       "        -0.44543701, -0.43981809]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.5924481 ,  13.55793904],\n",
       "       [ -1.68102479,  13.68552142],\n",
       "       [ -1.76907308,  13.46026398],\n",
       "       [ -0.72911001,   4.31120352],\n",
       "       [ -1.07387223,   4.57816873],\n",
       "       [ -1.53153146,   4.6258585 ],\n",
       "       [ -9.47322814,  -1.50456449],\n",
       "       [-10.15659693,  -1.32377295],\n",
       "       [-10.39192095,  -1.19414275],\n",
       "       [  3.27397598,  12.23850218],\n",
       "       [  1.43574763,  12.69707485],\n",
       "       [  1.20648237,  12.84544111],\n",
       "       [  3.47000219,   2.03193225],\n",
       "       [  2.53697989,   2.71688535],\n",
       "       [  2.08698647,   2.9566702 ],\n",
       "       [ -0.31903017,  -5.86620035],\n",
       "       [ -2.87375438,  -4.73509273],\n",
       "       [ -3.47395422,  -4.33710847],\n",
       "       [ 24.38920413,   2.66047088],\n",
       "       [ 19.95558747,   4.37093648],\n",
       "       [ 20.19858184,   4.8350319 ],\n",
       "       [ 25.00962905,  -2.50666374],\n",
       "       [ 21.98766611,  -1.50070254],\n",
       "       [ 20.38532457,  -0.89704656],\n",
       "       [ 15.15192396, -10.00399505],\n",
       "       [ 13.00905305,  -9.28981371],\n",
       "       [ 12.44231369,  -9.19289081],\n",
       "       [-16.00504165,  -1.0690811 ],\n",
       "       [-15.20050658,  -1.09246895],\n",
       "       [-14.75216331,  -1.34753218],\n",
       "       [-12.5289131 ,  -1.44266238],\n",
       "       [-11.06966272,  -1.89747334],\n",
       "       [-10.50909742,  -2.11785273],\n",
       "       [ -6.58819544,   5.4691788 ],\n",
       "       [ -5.67289441,   4.86509899],\n",
       "       [ -5.60691561,   4.84538816],\n",
       "       [  0.64700153,  -6.01460025],\n",
       "       [ -0.0798621 ,  -5.89923561],\n",
       "       [ -0.38717479,  -5.690385  ],\n",
       "       [ -3.16402411,  -0.63199878],\n",
       "       [ -3.37903492,  -0.7748686 ],\n",
       "       [ -3.04866201,  -0.97007026],\n",
       "       [  3.02645469,  -2.62011349],\n",
       "       [  2.67731729,  -2.57804142],\n",
       "       [  2.67152703,  -2.56584987],\n",
       "       [ -5.31397021,  -3.40787158],\n",
       "       [ -4.83266069,  -3.55405055],\n",
       "       [ -4.65594928,  -3.95844496],\n",
       "       [ -8.27756812,  -2.42068995],\n",
       "       [ -7.82713306,  -2.71532555],\n",
       "       [ -7.58414595,  -2.80193804],\n",
       "       [ -1.36468151,  -6.44940472],\n",
       "       [ -1.74296695,  -6.17045072],\n",
       "       [ -1.90499053,  -6.20916218]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds=pd.read_csv('salivatest.csv', header=0);\n",
    "\n",
    "S1=ds.ix[:,2:154] #instances\n",
    "#X1.head()\n",
    "S=S1.values\n",
    "\n",
    "# standardscale data\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "S_scaled=scaler.transform(S)\n",
    "\n",
    "pca = PCA(n_components=2).fit(S_scaled)\n",
    "S_2d = pca.transform(S_scaled)\n",
    "\n",
    "#define lables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "SL = ds.loc[:, 'Label'].values\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22455635,  0.47995068],\n",
       "       [-3.47243939, -0.6674534 ],\n",
       "       [ 5.86769417, -0.21566967],\n",
       "       [-1.52777418,  0.82392962],\n",
       "       [-2.04900251,  0.93456399],\n",
       "       [-3.68162762, -0.54660853],\n",
       "       [-3.18274629, -0.58904239],\n",
       "       [ 4.83147628, -0.516813  ],\n",
       "       [ 4.43897588,  0.29714272]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_2d, y, test_size=0.20, random_state=1)\n",
    "\n",
    "    \n",
    "svmClassifier_2d =svm.SVC(kernel='rbf', gamma=0.1, C=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmClassifier_2d.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_min, x_max = X_train[:, 0].min() - 1,   X_train[:,0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1,   X_train[:, 1].max() + 1\n",
    "xx,yy = np.meshgrid(np.arange(x_min, x_max, .1), np.arange(y_min, y_max, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = svmClassifier_2d.predict(np.c_[xx.ravel(),  yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    if y_train[i] == 0:\n",
    "        c1 = pl.scatter(X_train[i,0],X_train[i,1],c='r',marker='o', s = 40 )\n",
    "    elif y_train[i] == 1:\n",
    "        c2 = pl.scatter(X_train[i,0],X_train[i,1],c='g',marker='+', s = 50 )\n",
    "pl.legend([c1, c2], ['Nnegative','Positive'])\n",
    "pl.contour(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.8)\n",
    "pl.title('Support Vector Machine Decision Surface')\n",
    "pl.axis('off')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Fig 1\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 10  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X_train, y_train)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.01, C=C).fit(X_train, y_train)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X_train, y_train)\n",
    "sigmod_svc = svm.SVC(kernel='sigmoid', degree=3, C=C).fit(X_train, y_train)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "          'SVC with sigmod kernel',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel']\n",
    "\n",
    "\n",
    "for i, clf in enumerate((svc, sigmod_svc, rbf_svc, poly_svc)):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    pl.subplot(2, 2, i + 1)\n",
    "    pl.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    pl.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "\n",
    "    # Plot also the training points\n",
    "    pl.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=pl.cm.coolwarm)\n",
    "\n",
    "\n",
    "\n",
    "    pl.xlabel('Sepal length')\n",
    "    pl.ylabel('Sepal width')\n",
    "    pl.xlim(xx.min(), xx.max())\n",
    "    pl.ylim(yy.min(), yy.max())\n",
    "    pl.xticks(())\n",
    "    pl.yticks(())\n",
    "    pl.title(titles[i])\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#salivatest\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 10  # SVM regularization parameter\n",
    "\n",
    "clf= svm.SVC(kernel='rbf', gamma=0.01, C=C).fit(X_train, y_train)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "pl.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "\n",
    "for i in range(0, S_2d.shape[0]):\n",
    "        if SL[i] == 0:\n",
    "            c1 = pl.scatter(S_2d[i,0],S_2d[i,1],c='g',marker='o', s = 50 )\n",
    "        elif SL[i] == 1:\n",
    "            c2 = pl.scatter(S_2d[i,0],S_2d[i,1],c='b',marker='o', s = 50 )\n",
    "        elif SL[i] == 2:\n",
    "            c3 = pl.scatter(S_2d[i,0],S_2d[i,1],c='r',marker='*', s = 70 )\n",
    "                \n",
    "\n",
    "pl.xlabel('Sepal length')\n",
    "pl.ylabel('Sepal width')\n",
    "pl.xlim(xx.min(), xx.max())\n",
    "pl.ylim(yy.min(), yy.max())\n",
    "pl.xticks(())\n",
    "pl.yticks(())\n",
    "pl.title(\"Saliva Sample Test Result\")\n",
    "pl.legend([c1, c2,c3], ['Gmm3','Gmm3+Saliva','Gmm3+Saliva with 5mM Acetone'])\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "expected = y_test\n",
    "\n",
    "predicted = svmClassifier_2d.predict(X_test)\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=svm.SVC(kernel='rbf', gamma=0.01, C=10), \n",
    "                         X=X_2d, \n",
    "                         y=y, \n",
    "                         cv=10,\n",
    "                         n_jobs=10)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "The best parameters are {'C': 10.0, 'gamma': 0.01} with a score of 0.99\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib \n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "\n",
    "C_range = np.logspace(-5, 8, 14)\n",
    "gamma_range = np.logspace(-9, 4, 14)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=12)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# Now we need to fit a classifier for all parameters in the 2d version\n",
    "# (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "C_2d_range = [1,10, 100, 1000,10000]\n",
    "gamma_2d_range = [1e-4,1e-3, 1e-2,1e-1,1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(X_train, y_train)\n",
    "        classifiers.append((C, gamma, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize=(8, 6))\n",
    "#xx, yy = np.meshgrid(np.linspace(-3, 3, 200), np.linspace(-3, 3, 200))\n",
    "h=.1\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "    # evaluate decision function in a grid\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # visualize decision function for these parameters\n",
    "    plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "    # visualize parameter's effect on decision function\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "    #plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "    #plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=pl.cm.coolwarm)\n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], y_test, cmap=pl.cm.RdBu_r)\n",
    "    \n",
    "    for i in range(0, X_train.shape[0]):\n",
    "        if y_train[i] == 0:\n",
    "            c1 = pl.scatter(X_train[i,0],X_train[i,1],c='r',marker='o', s = 20 )\n",
    "        elif y_train[i] == 1:\n",
    "            c2 = pl.scatter(X_train[i,0],X_train[i,1],c='g',marker='+', s = 30 )\n",
    "    for i in range(0, X_test.shape[0]):\n",
    "        if y_test[i] == 0:\n",
    "            c3 = pl.scatter(X_test[i,0],X_test[i,1],c='b',marker='o', s = 20 )\n",
    "        elif y_test[i] == 1:\n",
    "            c4 = pl.scatter(X_test[i,0],X_test[i,1],c='m',marker='+', s = 30 )        \n",
    "        \n",
    "    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_2d_range = [10]\n",
    "gamma_2d_range = [1e-4, 1e-2, 1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(X_train, y_train)\n",
    "        classifiers.append((C, gamma, clf))\n",
    "h=.1\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "    # evaluate decision function in a grid\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # visualize decision function for these parameters\n",
    "    plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "    # visualize parameter's effect on decision function\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "    #plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "    #plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=pl.cm.coolwarm)\n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], y_test, cmap=pl.cm.RdBu_r)\n",
    "    \n",
    "    for i in range(0, X_train.shape[0]):\n",
    "        if y_train[i] == 0:\n",
    "            c1 = pl.scatter(X_train[i,0],X_train[i,1],c='r',marker='o', s = 20 )\n",
    "        elif y_train[i] == 1:\n",
    "            c2 = pl.scatter(X_train[i,0],X_train[i,1],c='g',marker='+', s = 30 )\n",
    "    for i in range(0, X_test.shape[0]):\n",
    "        if y_test[i] == 0:\n",
    "            c3 = pl.scatter(X_test[i,0],X_test[i,1],c='b',marker='o', s = 20 )\n",
    "        elif y_test[i] == 1:\n",
    "            c4 = pl.scatter(X_test[i,0],X_test[i,1],c='m',marker='+', s = 30 )        \n",
    "        \n",
    "    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17bed2adcf8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma=1\n",
    "C=10\n",
    "clf = SVC(C=C, gamma=gamma)\n",
    "clf.fit(X_train, y_train)\n",
    "h=.1\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    if y_train[i] == 0:\n",
    "        c1 = pl.scatter(X_train[i,0],X_train[i,1],c='r',marker='o', s = 20 )\n",
    "    elif y_train[i] == 1:\n",
    "        c2 = pl.scatter(X_train[i,0],X_train[i,1],c='g',marker='+', s = 30 )\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    if y_test[i] == 0:\n",
    "        c3 = pl.scatter(X_test[i,0],X_test[i,1],c='b',marker='o', s = 20 )\n",
    "    elif y_test[i] == 1:\n",
    "        c4 = pl.scatter(X_test[i,0],X_test[i,1],c='m',marker='+', s = 30 )     \n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Overfitting')\n",
    "pl.legend([c1, c2,c3,c4], ['Train Nnegative','Train Positive','test Nnegative','test Positive'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17bed6b7780>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma=1e-2\n",
    "C=10\n",
    "clf = SVC(C=C, gamma=gamma)\n",
    "clf.fit(X_train, y_train)\n",
    "h=.1\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    if y_train[i] == 0:\n",
    "        c1 = pl.scatter(X_train[i,0],X_train[i,1],c='r',marker='o', s = 20 )\n",
    "    elif y_train[i] == 1:\n",
    "        c2 = pl.scatter(X_train[i,0],X_train[i,1],c='g',marker='+', s = 30 )\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    if y_test[i] == 0:\n",
    "        c3 = pl.scatter(X_test[i,0],X_test[i,1],c='b',marker='o', s = 20 )\n",
    "    elif y_test[i] == 1:\n",
    "        c4 = pl.scatter(X_test[i,0],X_test[i,1],c='m',marker='+', s = 30 )     \n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Good Fitting')\n",
    "pl.legend([c1, c2,c3,c4], ['Train Nnegative','Train Positive','test Nnegative','test Positive'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17bedd68ba8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma=1e-4\n",
    "C=10\n",
    "clf = SVC(C=C, gamma=gamma)\n",
    "clf.fit(X_train, y_train)\n",
    "h=.1\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=pl.cm.coolwarm, alpha=0.5)\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    if y_train[i] == 0:\n",
    "        c1 = pl.scatter(X_train[i,0],X_train[i,1],c='r',marker='o', s = 20 )\n",
    "    elif y_train[i] == 1:\n",
    "        c2 = pl.scatter(X_train[i,0],X_train[i,1],c='g',marker='+', s = 30 )\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    if y_test[i] == 0:\n",
    "        c3 = pl.scatter(X_test[i,0],X_test[i,1],c='b',marker='o', s = 20 )\n",
    "    elif y_test[i] == 1:\n",
    "        c4 = pl.scatter(X_test[i,0],X_test[i,1],c='m',marker='+', s = 30 )     \n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Under Fitting')\n",
    "pl.legend([c1, c2,c3,c4], ['Train Nnegative','Train Positive','test Nnegative','test Positive'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "#\n",
    "# The score are encoded as colors with the hot colormap which varies from dark\n",
    "# red to bright yellow. As the most interesting scores are all located in the\n",
    "# 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "# as to make it easier to visualize the small variations of score values in the\n",
    "# interesting range while not brutally collapsing all the low score values to\n",
    "# the same color.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "            ('clf', SVC())])\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range, \n",
    "               'clf__kernel': ['linear']},\n",
    "                 {'clf__C': param_range, \n",
    "                  'clf__gamma': param_range, \n",
    "                  'clf__kernel': ['rbf']}]\n",
    "start = time()\n",
    "gs = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=10)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(gs.cv_results_['params'])))\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "            ('clf', SVC())])\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range, \n",
    "               'clf__kernel': ['linear']},\n",
    "                 ]\n",
    "start = time()\n",
    "gs = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=10)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(gs.cv_results_['params'])))\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "n_iter_search = 1000\n",
    "\n",
    "param_dist = {'clf__C': expon(), \n",
    "              'clf__kernel': ['linear','rbf','poly','sigmoid'],\n",
    "              'clf__gamma':expon(),\n",
    "             }\n",
    "start = time()\n",
    "rs = RandomizedSearchCV(estimator=pipe_svc,\n",
    "                        param_distributions=param_dist,\n",
    "                        n_iter=n_iter_search)\n",
    "\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "print(rs.best_score_)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = rs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmClassifier_2d.score(X_2d, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmClassifier_2d.cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
